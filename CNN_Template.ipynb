{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdQfPv4qVpfMbAsT2KKZJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IfMalthereturnawesome/colab-cnn-template/blob/main/CNN_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network (CNN) Template\n",
        "\n",
        "This template provides a structured layout for my CNN projects, \n",
        "including all essential steps and explanations."
      ],
      "metadata": {
        "id": "O7Lpws6qYhwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup Environment"
      ],
      "metadata": {
        "id": "o8W6lvwzUYDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "vawIuFN-Ug3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Version check for tensorflow"
      ],
      "metadata": {
        "id": "vfpJQ98yUm2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "dhn6oJgfUmJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Loading\n"
      ],
      "metadata": {
        "id": "yWq1RIjcU0T6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### EXAMPLE:\n",
        "\n",
        "\n",
        "```\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "f7fvmZOuYMZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your dataset here\n"
      ],
      "metadata": {
        "id": "B5q43HS9U9_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Cleaning"
      ],
      "metadata": {
        "id": "b2tj_mkkVQSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Perform data cleaning tasks such as handling missing data, removing duplicates etc.\n",
        "##### Use pandas and other libraries as required.\n",
        "\n",
        "##### EXAMPLE:\n",
        "###### Convert dataset to pandas DataFrame, check and handle duplicates and missing values\n",
        "\n",
        "```\n",
        "train_df = pd.DataFrame(train_images.reshape(-1, 28*28))\n",
        "train_df['label'] = train_labels\n",
        "train_df = train_df.drop_duplicates()\n",
        "train_df = train_df.dropna()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "f3Pce0MhXzYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clean data here\n"
      ],
      "metadata": {
        "id": "akq8df7bXoDg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data Preprocessing"
      ],
      "metadata": {
        "id": "H7vPfSbjYxrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Transform your data into the right format, normalize, and perform other necessary preprocessing tasks\n",
        "\n",
        "###### EXAMPLE:\n",
        "\n",
        "\n",
        "```\n",
        "train_images = train_images.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "test_images = test_images.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dh1w9wP_Y6Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data here"
      ],
      "metadata": {
        "id": "_5UG4edsY2qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Model Building"
      ],
      "metadata": {
        "id": "PRFFYE89ZPaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Build your CNN model here\n",
        "\n",
        "###### EXAMPLE:\n",
        "\n",
        "\n",
        "```\n",
        "model = Sequential([\n",
        "     Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "     Conv2D(64, (3, 3), activation='relu'),\n",
        "     Flatten(),\n",
        "     Dense(128, activation='relu'),\n",
        "     Dense(10, activation='softmax')\n",
        " ])\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "6ftITMXcZV2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build model here"
      ],
      "metadata": {
        "id": "E-wIUm7MZQfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Compile Model"
      ],
      "metadata": {
        "id": "VC7r-CsNZoY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Compile your model\n",
        "\n",
        "###### EXAMPLE:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-MKfxGPqZtLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model here"
      ],
      "metadata": {
        "id": "sNCCCgl5ZpOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Train Model"
      ],
      "metadata": {
        "id": "E_cZ1azIaUeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Compile your model\n",
        "\n",
        "###### EXAMPLE:\n",
        "\n",
        "```\n",
        "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nscO4nLhaPEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train model here"
      ],
      "metadata": {
        "id": "bzUScdsrabN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Model Prediction\n"
      ],
      "metadata": {
        "id": "c9Rh6eX4c8z0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training the model, we use it to predict on our test set\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "If your model outputs probabilities and you want to convert these to class labels, you might also do something like:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "cud-0SPvc_M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict model here"
      ],
      "metadata": {
        "id": "infxde-bdqz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Model Evaluation"
      ],
      "metadata": {
        "id": "w1Xyh9G9aqTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Evaluate your model and generate performance metrics\n",
        "\n",
        "###### EXAMPLE:\n",
        "###### Get the model predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pred_labels = np.argmax(model.predict(test_images), axis=-1)\n",
        "test_labels_1D = np.argmax(test_labels, axis=-1)\n",
        "cm = confusion_matrix(test_labels_1D, pred_labels)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.show()\n",
        "print(classification_report(test_labels_1D, pred_labels))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-39nuqMpa7hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model here"
      ],
      "metadata": {
        "id": "vyjwlUv1asw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Model Optimization/Tuning (Optional)"
      ],
      "metadata": {
        "id": "ZZOMyHevbORO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ###### If necessary, perform hyperparameter tuning or other optimization methods to improve your model\n",
        "\n",
        " ###### EXAMPLE:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        " from kerastuner.tuners import RandomSearch\n",
        "\n",
        " def build_model(hp):\n",
        "     model = Sequential()\n",
        "     model.add(Conv2D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16), \n",
        "                      kernel_size=hp.Choice('conv_1_kernel', values=[3,5]), \n",
        "                      activation='relu',\n",
        "                      input_shape=(28, 28, 1)\n",
        "     ))\n",
        "     model.add(Conv2D(filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16), \n",
        "                      kernel_size=hp.Choice('conv_2_kernel', values=[3,5]), \n",
        "                      activation='relu'\n",
        "     ))\n",
        "     model.add(Flatten())\n",
        "     model.add(Dense(units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16), \n",
        "                     activation='relu'\n",
        "     ))\n",
        "     model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "     model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])), \n",
        "                   loss='categorical_crossentropy', \n",
        "                   metrics=['accuracy'])\n",
        "    \n",
        "     return model\n",
        "\n",
        " tuner = RandomSearch(\n",
        "     build_model,\n",
        "     objective='val_accuracy',\n",
        "     max_trials=5,\n",
        "     directory='output',\n",
        "     project_name=\"MNIST_CNN\"\n",
        " )\n",
        "\n",
        " tuner.search(train_images, train_labels, epochs=3, validation_split=0.1)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "lTBVhAYSbWqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune/optimize model here"
      ],
      "metadata": {
        "id": "6VGX5p4ObSyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Repeat subsequent steps if tuning/optimizing (optional)"
      ],
      "metadata": {
        "id": "aP64Sk3mb3kA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here are the steps you should take after model optimization:\n",
        "\n",
        "1.   **Re-train the model:** Once you have determined the optimal hyperparameters or architecture adjustments, you should re-train your model with these settings. This includes fitting the model on your training data once again.\n",
        "2.   **Re-evaluate the model:** After re-training, you should assess the performance of the optimized model. This often means re-computing evaluation metrics such as accuracy, precision, recall, F1-score, etc., as well as generating new confusion matrices or other diagnostic plots. You might find that the model's performance on certain metrics has improved.\n",
        "3.   **Re-predict (if necessary):** If you have a separate test set or new data that you want to make predictions on, you should use the optimized model to make these predictions. Since the model has been updated, the predictions might be more accurate.\n",
        "\n",
        "\n",
        "\n",
        "**Note**: Keep in mind that the goal of optimization/tuning is to improve the model's performance, particularly on unseen data. Therefore, it's important to make sure that you're not just fitting the model to the training data too closely (overfitting), which could result in poor performance on new data. Cross-validation during the tuning process can help mitigate this risk."
      ],
      "metadata": {
        "id": "2Y8ZcQMLcCSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Model Deployment (Optional)"
      ],
      "metadata": {
        "id": "ar64lWfBdQTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you plan on deploying your model, save your model here and download it if necessary\n",
        "\n",
        "EXAMPLE:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model.save('my_model.h5')\n",
        "\n",
        "## To download the model from colab:\n",
        "from google.colab import files\n",
        "files.download('my_model.h5') \n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "t0rEbDIadThU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save model here"
      ],
      "metadata": {
        "id": "sjSRclTLeJGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Conclusions"
      ],
      "metadata": {
        "id": "upkTO2yuddNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Include your conclusions, findings, and any other relevant comments\n",
        "\n",
        "EXAMPLE:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "print(\"The final accuracy of the model is: \", accuracy)\n",
        "print(\"The model performed best on the following classes: \", best_classes)\n",
        "print(\"Areas for further investigation include: \", further_investigation)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "1VT-mDw4deek"
      }
    }
  ]
}